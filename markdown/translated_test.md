# Punica: 다중 테넌트 LoRA 서빙 시스템

Lequn Chen $^{* 1}$ Zihao Ye $^{* 1}$ Yongji Wu $^{2}$ Danyang Zhuo ${ }^{2}$ Luis Ceze ${ }^{1}$ Arvind Krishnamurthy $^{1}$

#### 초록

낮은 순위 적응(Low-rank adaptation, LoRA)은 사전 훈련된 모델들을 특정 도메인에 맞추기 위한 중요하고 인기 있는 방법으로 자리 잡고 있습니다. 우리는 공유 GPU 클러스터에서 여러 LoRA 모델을 서비스할 수 있는 시스템인 Punica를 소개합니다. Punica는 다양한 LoRA 모델에 대한 GPU 연산을 일괄 처리할 수 있는 새로운 CUDA 커널 설계를 포함하고 있습니다. 이를 통해 GPU는 다수의 다른 LoRA 모델들을 서비스하면서도 기본 사전 훈련된 모델의 단일 복사본만을 유지할 수 있게 되어, 메모리와 계산 측면에서 GPU 효율성을 크게 높입니다. 우리의 스케줄러는 다중 테넌트 LoRA 서빙 워크로드를 공유 GPU 클러스터에서 통합합니다. 고정된 크기의 GPU 클러스터를 사용하여 평가한 결과, Punica는 토큰당 2 밀리초(ms)의 지연 시간을 더하는 것만으로도 최신 LLM 서빙 시스템에 비해 여러 LoRA 모델을 서비스할 때 12배 높은 처리량을 달성하는 것으로 나타났습니다. Punica는 https://github.com/punica-ai/punica 에서 오픈 소스로 제공됩니다.

## 1 서론

낮은 순위 적응(Low-rank adaptation, LoRA)은 최소한의 훈련 데이터로 사전 훈련된 대규모 언어 모델(Large language models, LLMs)을 특정 도메인의 과제에 특화시키는 방법으로 점점 더 인기를 얻고 있습니다. LoRA는 사전 훈련된 모델의 가중치를 유지하면서 변형 아키텍처(Transformer architecture)의 각 레이어에 학습 가능한 순위 분해 행렬을 도입함으로써 학습 가능한 매개변수의 수를 크게 줄이고, 테넌트가 저렴한 비용으로 다른 LoRA 모델들을 훈련할 수 있도록 합니다. LoRA는 많은 인기 있는 파인튜닝 프레임워크에 통합되었습니다(Mangrulkar et al., 2022). 그 결과, ML 제공자들은 그들의 테넌트들의 요구에 맞추어 동시에 다수의 특화된 LoRA 모델들을 서비스해야 하는 상황에 처하게 되었습니다.

마치 각 LoRA 모델이 처음부터 독립적으로 훈련된 것처럼 서빙하는 것은 GPU 자원을 낭비합니다. 각 LoRA 모델을 서비스하는 데에 $k$ 개의 GPU가 필요하다고 가정할 때, $n$ 개의 다양한 LoRA 모델을 서비스하는 데에는 $k \times n$ 개의 GPU가 필요해 보일 것입니다. 이 직설적인 접근법은 이 LoRA 모델들이 동일한 사전 훈련된 모델로부터 비롯된 것이므로, 이들 간의 가중치 상관 관계의 잠재력을 간과합니다.

우리는 다수의 서로 다른 LoRA 모델들을 효율적으로 서비스하는 시스템이 세 가지 디자인 지침을 따라야 한다고 믿습니다. (G1) GPU는 비싸고 희소한 자원이기 때문에, 전체적인 GPU 사용률을 높이기 위해 적은 수의 GPU에 다중 테넌트 LoRA 서빙 워크로드를 통합해야 합니다. (G2) 이미 이전 연구들이 지적한 바와 같이(Yu et al., 2022), 일괄 처리는 ML 워크로드를 통합하여 성능과 GPU 사용률을 향상시키는 가장 효과적인 접근 방법 중 하나입니다. 그러나, 이는 재[^0]

### 1. 도입부

LoRA(Language Model Refinement via Add-ons) 모델을 공동으로 사용하는 작업을 관리하는 것은 세 가지 가이드라인이 필요합니다. (G1) LoRA는 훈련된 대규모 언어 모델(large language model)의 미세한 일부만 수정하여 동작합니다. 이러한 점을 활용하면, 한 번의 실행에 다양한 LoRA 모델을 효율적으로 서비스할 수 있습니다. (G2) LoRA를 사용하는 대부분의 사용자들은 동일한 모델을 요청하기 때문에, 다양한 LoRA 모델을 위한 배치(batching) 기능을 활성화해야 합니다. (G3) 모델 서비스에서 가장 비용이 많이 드는 단계는 디코드(decode) 단계입니다. 따라서 디코드 단계의 성능에만 집중할 필요가 있습니다. 모델 서비스의 다른 측면들은 그리 중요하지 않으며, 예를 들어 LoRA 모델의 가중치를 요청 시 불러오는(on-demand loading) 등의 간단한 기법을 적용할 수 있습니다.

이 세 가지 방침에 근거하여, 공유 GPU 클러스터에서 다중 사용 환경을 위한 LoRA 모델 서비스 프레임워크인 Punica를 설계하고 구현합니다. 주요한 신규성은 새로운 CUDA 커널인 세그먼트 집합 행렬-벡터 곱셈(Segmented Gather Matrix-Vector Multiplication, SGMV)의 설계에 있습니다. SGMV는 GPU 연산을 배치하여 동시에 다수의 상이한 LoRA 모델을 실행할 수 있게 합니다. SGMV를 사용하면, GPU는 사전 훈련된 모델의 단 하나의 사본만 메모리에 저장하면 되므로, 메모리 및 계산 측면에서 GPU 효율성을 상당히 향상시킵니다. 이 새로운 CUDA 커널과 함께 우리는 최신 시스템 최적화 기술들을 결합합니다.

SGMV는 상이한 LoRA 모델들로부터의 요청을 배치 처리할 수 있으며, 놀랍게도, 동일한 LoRA 모델을 배치 처리하는 것과 다른 LoRA 모델을 배치 처리하는 것 사이에 성능 차이가 거의 없다는 것을 관찰합니다. 동시에, LoRA 모델의 요청 시 불러오기는 밀리초 단위의 지연시간만을 가집니다. 이는 Punica가 어떤 LoRA 모델이 이미 GPU에서 실행 중인지에 구애받지 않고 사용자의 요청을 소수의 GPU에 집중시킬 수 있는 유연성을 제공합니다.

그러므로 Punica는 다음 두 가지 방식으로 다중 사용자 워크로드를 스케줄링합니다. 새로운 요청의 경우, Punica는 요청을 활성화된 소수의 GPU로 라우팅하여 그들이 전체 용량을 달성하도록 합니다. 기존 GPU가 완전히 활용되는 경우에만 Punica는 추가 GPU 자원을 할당합니다. 기존 요청에 대해서는, Punica는 주기적으로 점검하여

![](https://cdn.mathpix.com/cropped/2023_11_23_b73af3ccb669e34fc265g-2.jpg?height=325&width=805&top_left_y=233&top_left_x=194)

그림 1. Prefill 단계와 Decode 단계에서의 배치 효과

집중화를 위해 이를 이동합니다. 이를 통해 Punica에 할당된 GPU 자원을 해제할 수 있습니다.

NVIDIA A100 GPU 클러스터에서 Llama2 7B, 13B, 그리고 70B 모델(Touvron et al., 2023)로부터 적응된 LoRA 모델들을 평가합니다. 동일한 GPU 자원을 사용할 때, Punica는 토큰당 $2 \mathrm{~ms}$의 지연시간만을 추가하는 동안 최신의 LLM 서비스 시스템들과 비교하여 $12배$ 더 높은 처리량을 달성합니다.

이 논문은 다음과 같은 기여를 합니다:

- 우리는 서로 다른 LoRA 모델들의 요청을 배치 처리라는 기회를 식별합니다.
- 우리는 동시에 여러 LoRA 모델을 실행하기 위한 효율적인 CUDA 커널을 설계하고 구현합니다.
- 우리는 다중 사용자 LoRA 워크로드를 집중화하기 위한 새로운 스케줄링 메커니즘을 개발합니다.


## 2 배경

우선 변압기(Transformer) 모델의 텍스트 생성 과정을 소개하겠습니다. 그런 다음 변압기 모델의 저랭크 적응(Low-Rank Adaptation, LoRA)에 대해 설명하겠습니다.

### 2.1 변압기와 텍스트 생성

변압기 기반 LLM은 토큰의 시퀀스를 처리합니다. 토큰은 대략 영어 단어의 $3 / 4$에 해당합니다. LLM의 작업은 두 단계로 이루어집니다. 사전채우기(prefill) 단계는 사용자 프롬프트를 받아 후속 토큰과 키-값 캐시(Key-Value cache, $\mathrm{KvCache}$)를 생성합니다. 해독(decode) 단계는 토큰과 $\mathrm{KvCache}$를 받아 또 다른 토큰을 생성하고 $\mathrm{KvCache}$에 열을 추가합니다. 해독 단계는 반복적인 과정입니다. 생성된 토큰은 다음 단계의 입력이 됩니다. 이 과정은 엔드-오브-시퀀스 토큰이 생성될 때까지 끝나지 않습니다.

변압기 블록에는 셀프-어텐션(self-attention) 계층과 다중계층 퍼셉트론(multilayer perceptron, MLP)이 포함되어 있습니다. 프롬프트의 길이를 $s$라 가정하고 어텐션 헤드 차원을 $d$라고 할 때, 사전채우기 단계에서의 셀프-어텐션 계층의 계산은 $(s, d) \times(d, s) \times(s, d)$이며, MLP의 계산은 $(s, h) \times(h, h)$입니다. 해독 단계의 경우, $s$가 지난 시퀀스 길이를 나타낸다고 가정할 때, 셀프-어텐션 계층의 계산은 $(1, d) \times(d, s+1) \times(s+1, d)$이고 MLP의 계산은 $(1, h) \times(h, h)$입니다. 해독 단계는 입력이 단일 벡터이기 때문에 GPU 사용률이 낮습니다.

그림 1은 서로 다른 배치 크기에 대한 사전채우기 단계와 해독 단계의 지연 시간을 보여줍니다. 사전채우기 단계 동안 GPU의 계산 능력이 완전히 사용됩니다. 사전채우기 지연 시간은 배치 크기에 비례합니다. 그러나 해독 단계에서는 그렇지 않습니다. 배치 크기를 1에서 32로 늘렸을 때, 짧은 시퀀스의 경우 해독 단계 지연 시간은 $11 \mathrm{~ms}$에서 $13 \mathrm{~ms}$로 증가하며, 더 긴 시퀀스의 경우 $17 \mathrm{~ms}$에서 $34 \mathrm{~ms}$로 증가합니다. 이는 배치 처리가 해독 단계의 GPU 사용률을 크게 향상시킬 수 있음을 의미합니다. Orca(Yu et al., 2022)는 이 기회를 활용하여 효율적인 LLM 서비스 시스템을 구축했습니다. 특히 긴 출력 길이 응답에 대한 서비스 지연 시간을 주로 결정하는 해독 단계에서 이러한 배치 처리는 매우 중요합니다.

### 2.2 저랭크 적응 (LoRA)

미세조정(Fine-tuning)은 사전 훈련된 모델이 새로운 도메인이나 새로운 작업에 적응하거나 신규 훈련 데이터로 개선되도록 합니다. 그러나 LLM이 크기 때문에 모든 모델 매개변수를 세밀하게 조정하는 것은 자원이 많이 듭니다.

Low-Rank Adaptation(LoRA)(Hu 외, 2022)은 미세조정(fine-tuning)하는 동안에 필요한 훈련 매개 변수의 수를 크게 줄입니다. 중요한 관찰은 사전 훈련된 모델(pre-trained model)과 미세조정 후의 모델 사이의 가중치 차이(weight difference)가 낮은 계수(low rank)를 가진다는 것입니다. 이러한 가중치 차이는 두 개의 작고 조밀한(dense) 행렬의 곱으로 나타낼 수 있습니다. 그러므로 LoRA 미세조정은 작은 조밀한 신경망(neural network)을 훈련하는 것과 유사해집니다. 정식으로, 사전 훈련된 모델의 가중치를 $W \in \mathbb{R}^{h_{1} \times h_{2}}$라고 하면, LoRA 미세조정은 두 행렬 $A \in \mathbb{R}^{h_{1} \times r}$와 $B \in \mathbb{R}^{r \times h_{2}}$을 훈련시키는데, 여기서 $r$은 LoRA 계수(LoRA Rank)입니다. $W+A B$는 미세조정된 모델을 위한 새로운 가중치입니다. LoRA 계수는 보통 원래 차원보다 훨씬 작습니다(예를 들어, 4096 대신에 16). 빠른 미세조정 외에도, LoRA는 아주 낮은 저장소와 메모리 부담이 있습니다. 미세조정된 모델은 모델 가중치에 추가되는 것이 $0.1 \%$에서 $1 \%$ 뿐입니다. LoRA는 트랜스포머 층(transformer layer) 안의 모든 조밀한 프로젝션에 주로 적용됩니다(Dettmers 외, 2023), 여기에는 주의 집중 메커니즘(attention mechanism)과 MLP에서의 Query-Key-Value-Output 프로젝션들이 포함됩니다. 자기 주의 집중(self-attention) 연산 자체는 어떤 가중치도 포함하고 있지 않다는 점에 유의해야 합니다.

공유된 GPU 클러스터에 효율적으로 다중 테넌트 LoRA 모델을 어떻게 제공할까요? LoRA는 대규모 언어 모델(LLM)을 미세조정하는 효율적인 알고리즘을 제공합니다. 이제 문제는 이러한 LoRA 모델을 어떻게 효율적으로 제공할까 하는 것입니다. 한 가지 접근 방법은 각각의 LoRA 모델을 독립적인 모델로 간주하고 전통적인 LLM 서비스 시스템(예: vLLM)을 사용하는 것입니다. 그러나, 이것은 다양한 LoRA 모델들 사이에 공유되는 가중치를 간과하는 것입니다.

![](https://cdn.mathpix.com/cropped/2023_11_23_b73af3ccb669e34fc265g-3.jpg?height=336&width=1678&top_left_y=236&top_left_x=191)

그림 8. LoRA 연산자 구현에 대한 마이크로벤치마크(Microbenchmark). ${ }^{\dagger}$Gather 와 BMM은 참조를 위해 별도로 측정됩니다.

![](https://cdn.mathpix.com/cropped/2023_11_23_b73af3ccb669e34fc265g-3.jpg?height=322&width=1688&top_left_y=690&top_left_x=194)

그림 9. 다양한 LoRA 계수에서의 LoRA 연산자에 대한 마이크로벤치마크.

전반적으로, SGMV는 작업 부하에 관계없이 기준 구현(baseline implementations)보다 크게 우수한 성능을 보입니다.

저희는 또한 Testbed #1에서 다양한 LoRA 순위에 대한 마이크로벤치마크를 진행하였습니다. 그림 9는 LoRA 순위 8, 16, 32, 그리고 64의 지연 시간을 보여줍니다. Distinct 케이스에서는 지연 시간이 점차 증가합니다. 단일 요청 배치의 경우 모든 네 순위에 대해 대략 42 마이크로초($42 \mu$ s)의 지연 시간이 발생하며, 배치 크기 64의 경우 각각 72 마이크로초($72 \mu \mathrm{s}$), 75 마이크로초($75 \mu \mathrm{s}$), 89 마이크로초($89 \mu \mathrm{s}$), 그리고 118 마이크로초($118 \mu \mathrm{s}$)로 증가합니다. 작업 부하에 가중치 공유(Uniform, Skewed, 그리고 Identical)가 있는 경우, 배치 크기 1에서 64까지 대략 42 마이크로초($42 \mu$ s)에서 45 마이크로초($45 \mu \mathrm{s}$) 사이의 지연 시간이 거의 동일하게 유지됩니다.

### Transformer 레이어 벤치마크
다음으로, LoRA 연산자를 적용한 뒤의 트랜스포머 레이어 성능을 평가합니다. LLM이 대략적으로 트랜스포머 레이어의 스택으로 이루어져있기 때문에, 레이어 성능이 전체 모델 성능을 결정합니다. 우리는 Testbed #1에서 7B와 13B 모델 구성과 시퀀스 길이 512와 2048을 기반으로 레이어 벤치마크를 실행합니다. 그림 10은 레이어 지연 시간을 보여줍니다. 시퀀스 길이가 짧을 때, 배치 효과가 강합니다. 시퀀스 길이가 512일 때, 배치 크기가 1에서 32로 증가하는 경우 지연 시간은 단지 72%만 증가합니다. 시퀀스가 길어질 때, 셀프-어텐션(self-attention)이 더 긴 시간이 걸리고, 이는 레이어별 배치 효과를 감소시킵니다.

커널 마이크로벤치마크와는 대조적으로, 다른 작업 부하에서 레이어 지연 시간이 대략적으로 동일하다는 것을 알아차립니다. 이는 LoRA 부가 기능의 계산 시간이 백본 밀집 프로젝션(dense projection)과 셀프-어텐션에 비해 작기 때문입니다. 이러한 LoRA-모델-중립적인 성능 특성은 다른 LoRA 모델들을 하나의 모델처럼 스케줄링 할 수 있게 해줍니다. 우리의 스케줄링 알고리즘은 그 후 개별 LoRA 모델 배치가 아닌 전체 처리량에 초점을 맞출 수 있고, 이는 바로 우리가 Punica를 어떻게 설계하는지에 부합합니다.

### 7.2 텍스트 생성

다음으로, Punica와 기준 시스템들의 텍스트 생성 성능을 연구합니다.

단일 GPU에서 7B와 13B 모델 서빙 단일 GPU에서 Punica와 기준 시스템을 사용하여 Testbed #1에서 텍스트 생성성능을 평가합니다. 단일-GPU 성능은 클러스터 전반적인 배치를 위한 기준 사례로 사용됩니다. 우리는 1000개의 요청(약 101k 토큰 생성)을 생성하고 각 시스템을 선착순 방식으로 배치하도록 제한합니다. 최대 배치 크기는 모든 시스템에 대해 32로 설정됩니다. Punica는 다양한 LoRA 모델에 걸쳐 배치할 수 있고, 기준 시스템은 동일한 LoRA 모델에 대한 요청만 배치할 수 있습니다.

![Figure 11 (a)](image-url-here)과 ![Figure 11 (b)](image-url-here)는 각각 7B 모델과 13B 모델에서의 결과를 보여줍니다. Punica(푸니카)는 작업량에 관계없이 일관되게 높은 처리량을 제공합니다. Punica(푸니카)는 7B 모델에서 1044 $\mathrm{토큰/초}$, 13B 모델에서는 693 토큰/초(tok/s)를 달성합니다. 대부분의 기준 시스템들이 Identical case(동일 케이스)에서는 상대적으로 높은 처리량을 달성할 수 있지만, 여러 LoRA(LoRA) 모델이 있을 때 그 성능이 저하됩니다.

Distinct case(독립 케이스)에서는 모든 기준 시스템들이 배치 크기(batch size) 1로 실행되므로 처리량이 낮습니다. Uniform case(동일 분포 케이스)와 Skewed case(치우친 케이스)에서는 기준 시스템들의 대부분의 배치가 매우 작은 배치 크기(1-3)를 가지기 때문에 처리량이 낮다는 것을 설명합니다.

[^0]:    ${ }^{*}$ 동등한 기여 ${ }^{1}$ 워싱턴 대학교(University of Washington) ${ }^{2}$ 듀크 대학교(Duke University). 연락처: Lequn Chen $<$ lqchen@cs.washington.edu $>$.

